new_data <- list("x" = power_x, "y" = power_y)
}
}
power_transformed = power_transformation(data$Commute, data$Population)
data_transformed <- power_transformed(-0.5, -0.5)
plot1 <- ggplot(data) +
geom_point(
aes(x = Commute,
y = Population,
alpha = 0.5)
) +
labs(
title = "Original",
x = "Commute",
y = "Population"
)
plot2 <- ggplot(data) +
geom_point(
aes(x = data_transformed$x,
y = data_transformed$y,
alpha = 0.5)
) +
labs(
title = "Power-Transformed Plot",
x = "Commute alpha_x = -0.5",
y = "Population alpha_y = -0.5"
)
grid.arrange(plot1, plot2, nrow = 1)
knitr::opts_chunk$set(echo = TRUE)
L <- function(theta, x, y) {
power_x <- powerfun(x + 1, theta[1])
power_y <- powerfun(y + 1, theta[2])
attribute <- 1 - cor(power_x, power_y, method = "pearson")^2
}
theta <- c(1,1)
L(theta, data$Population, data$Commute)
View(L)
View(L)
theta <- c(1,1)
attribute_L <- L(theta, data$Population, data$Commute)
nlminbnlminb
?nlminb
L <- function(theta) {
x <- data$Population
y <- data$Commute
power_x <- powerfun(x + 1, theta[1])
power_y <- powerfun(y + 1, theta[2])
attribute <- 1 - cor(power_x, power_y, method = "pearson")^2
}
optimal_theta <- nlminb(start=c(1,1), objective=L)
View(optimal_theta)
optimal_theta
optimal_theta <- nlminb(start=c(1,1), objective=L)
optimal_theta$par
optimal_theta$par[1]
plot1 <- ggplot(data) +
geom_point(
aes(x = Commute,
y = Population,
alpha = 0.5)
) +
labs(
title = "Original",
x = "Commute",
y = "Population"
)
plot2 <- ggplot(data) +
geom_point(
aes(x = powerfun(data$Population +1, optimal_theta$par[1]),
y = powerfun(data$Commute +1, optimal_theta$par[2]),
alpha = 0.5)
) +
labs(
title = "Power-Transformed Plot with Optimal Theta",
x = "Commute",
y = "Population"
)
ggplot(data) +
geom_point(
aes(x = Commute,
y = Population,
alpha = 0.5)
) +
labs(
title = "Original",
x = "Commute",
y = "Population"
)
ggplot(data) +
geom_point(
aes(x = powerfun(data$Population +1, optimal_theta$par[1]),
y = powerfun(data$Commute +1, optimal_theta$par[2]),
alpha = 0.5)
) +
labs(
title = "Power-Transformed Plot with Optimal Theta",
x = "Commute",
y = "Population"
)
original_correlation <- cor(data$Population, data$Commute, method = "pearson")
original_correlation <- cor(data$Population, data$Commute, method = "pearson")
original_correlation
original_correlation <- cor(data$Population, data$Commute, method = "pearson")
message("The correlation coefficient for the original data is ", original_correlation)
transformed_correlation <- cor(transformed_pop, transformed_commute, method = "pearson")
ggplot(data) +
geom_point(
aes(x = Commute,
y = Population,
alpha = 0.5)
) +
labs(
title = "Original",
x = "Commute",
y = "Population"
)
transformed_pop <- powerfun(Population +1, optimal_theta$par[1])
ggplot(data) +
geom_point(
aes(x = Commute,
y = Population,
alpha = 0.5)
) +
labs(
title = "Original",
x = "Commute",
y = "Population"
)
transformed_pop <- powerfun(data$Population +1, optimal_theta$par[1])
transformed_commute <- powerfun(data$Commute +1, optimal_theta$par[2])
ggplot(data) +
geom_point(
aes(x = transformed_pop,
y = transformed_commute,
alpha = 0.5)
) +
labs(
title = "Power-Transformed Plot with Optimal Theta",
x = "Commute",
y = "Population"
)
original_correlation <- cor(data$Population, data$Commute, method = "pearson")
message("The correlation coefficient for the original data is ", original_correlation)
transformed_correlation <- cor(transformed_pop, transformed_commute, method = "pearson")
message("The correlation coefficient for the transformed data is ", transformed_correlation)
length(data$Population)
knitr::opts_chunk$set(echo = TRUE)
par(mfrow=c(1,2))
plot(delta, main="Influence for Correlation Coefficient", pch=19,
col=adjustcolor("black", alpha = 0.2) )
correlation_coefficient <- function(y) {
cor(y, data$Commute, method = "pearson")
}
delta = numeric(length(data$Population))
for (i in 1:length(data$Population)) {
## y[-i] removes the ith element from a vector
delta[i] = correlation_coefficient(data$Population) - correlation_coefficient(data$Population[-i]))
correlation_coefficient <- function(y) {
cor(y, data$Commute, method = "pearson")
}
delta = numeric(length(data$Population))
for (i in 1:length(data$Population)) {
## y[-i] removes the ith element from a vector
delta[i] = correlation_coefficient(data$Population) - correlation_coefficient(data$Population[-i])
}
correlation_coefficient <- function(y) {
cor(y, data$Commute, method = "pearson", use='complete.obs')
}
delta = numeric(length(data$Population))
for (i in 1:length(data$Population)) {
## y[-i] removes the ith element from a vector
delta[i] = correlation_coefficient(data$Population) - correlation_coefficient(data$Population[-i])
}
?cor
knitr::opts_chunk$set(echo = TRUE)
powerfun <- function(x, alpha) {
if(sum(x <= 0) > 1) stop("x must be positive")
if (alpha == 0)
log(x)
else if (alpha > 0) {
x^alpha
} else -x^alpha
}
power_transformation <- function(x, y) {
function(alpha_x, alpha_y) {
power_x <- powerfun(x + 1, alpha_x)
power_y <- powerfun(y + 1, alpha_y)
new_data <- list("x" = power_x, "y" = power_y)
}
}
power_transformed = power_transformation(data$Commute, data$Population)
data_transformed <- power_transformed(-0.5, -0.5)
plot1 <- ggplot(data) +
geom_point(
aes(x = Commute,
y = Population,
alpha = 0.5)
) +
labs(
title = "Original",
x = "Commute",
y = "Population"
)
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
library("gridExtra")
data <- read.csv("EconomicMobility.csv")
data$PopulationGroup <- cut(data$Population, breaks=c(0, 100000, 500000, 5000000, 5000001), labels=c("<=100,000","(100,000-500,000]","(500,000, 5,000,000]", ">=5,000,000"))
data$CommuteGroup <- cut(data$Commute, breaks=c(0, 0.25, 0.5, 0.75, 0.751), labels=c("<=0.25,000","(0.25-0.50]","(0.50, 0.75]", ">=0.75"))
plot1 <- ggplot(data) +
geom_point(
aes(x = Longitude,
y = Latitude,
color = PopulationGroup,
alpha = 0.5)
) +
labs(
title = "Population Groups",
x = "Longitude",
y = "Latitude"
)
plot2 <- ggplot(data) +
geom_point(
aes(x = Longitude,
y = Latitude,
color = CommuteGroup,
alpha = 0.5)
) +
labs(
title = "Commute Groups",
x = "Longitude",
y = "Latitude"
)
grid.arrange(plot1, plot2, nrow = 2)
knitr::opts_chunk$set(echo = TRUE)
powerfun <- function(x, alpha) {
if(sum(x <= 0) > 1) stop("x must be positive")
if (alpha == 0)
log(x)
else if (alpha > 0) {
x^alpha
} else -x^alpha
}
power_transformation <- function(x, y) {
function(alpha_x, alpha_y) {
power_x <- powerfun(x + 1, alpha_x)
power_y <- powerfun(y + 1, alpha_y)
new_data <- list("x" = power_x, "y" = power_y)
}
}
power_transformed = power_transformation(data$Commute, data$Population)
data_transformed <- power_transformed(-0.5, -0.5)
plot1 <- ggplot(data) +
geom_point(
aes(x = Commute,
y = Population,
alpha = 0.5)
) +
labs(
title = "Original",
x = "Commute",
y = "Population"
)
plot2 <- ggplot(data) +
geom_point(
aes(x = data_transformed$x,
y = data_transformed$y,
alpha = 0.5)
) +
labs(
title = "Power-Transformed Plot",
x = "Commute alpha_x = -0.5",
y = "Population alpha_y = -0.5"
)
grid.arrange(plot1, plot2, nrow = 1)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("EconomicMobility.csv")
# Prerequisite functions all of which we discussed in class
gradientDescent <- function(theta,
rhoFn,
gradientFn,
lineSearchFn,
testConvergenceFn,
maxIterations = 100,
tolerance = 1E-6,
relative = FALSE,
lambdaStepsize = 0.01,
lambdaMax = 0.5) {
for (i in 1:maxIterations) {
g         <- gradientFn(theta) # Unnormalized gradient.
glength   <- sqrt(sum(g ^ 2))  # Gradient vector length.
g         <- g / glength       # Unit vector gradient.
lambda    <- lineSearchFn(theta, rhoFn, g,
lambdaStepsize = lambdaStepsize,
lambdaMax = lambdaMax)
thetaNew  <- theta - lambda * g
converged <- testConvergenceFn(thetaNew, theta,
tolerance = tolerance,
relative = relative)
theta = thetaNew #Reza added this update
if (converged) break
}
## Return information about the gradient descent procedure.
return(list(theta = theta, converged = converged,
iteration = i, fnValue = rhoFn(theta)))
}
gridLineSearch <- function(theta,
rhoFn,
g,
lambdaStepsize = 0.01,
lambdaMax = 1) {
## Define equally-spaced grid of lambdas to search over.
lambdas <- seq(from = 0, by = lambdaStepsize, to = lambdaMax)
## Evaluate the objective rho at each such lambda.
rhoVals <- Map(function(lambda) {rhoFn(theta - lambda * g)}, lambdas)
## Return the lambda that gave the minimum objective.
return(lambdas[which.min(rhoVals)])
}
testConvergence <- function(thetaNew,
thetaOld,
tolerance = 1E-10,
relative = FALSE) {
sum(abs(thetaNew - thetaOld)) <
if (relative) tolerance * sum(abs(thetaOld)) else tolerance
}
rhoFn <- function(x) {
alpha <- x[1]
beta <- x[2]
loglikelihood <- 0
P <- data$Commute
for (y in P) {
loglikelihood <- loglikelihood + alpha*log(beta) + (alpha -1)*log(y) - log(gamma(alpha)) - y*beta
}
return(loglikelihood)
}
gradientFn <- function(x) {
alpha <- x[1]
beta <- x[2]
result1 = result2 = 0
P <- data$Commute
for (y in P) {
result1 = result1 + log(beta) + log(y) + digamma(alpha)
result2 = result2 + alpha/beta - y
}
return(c(result1, result2))
}
result <- gradientDescent(theta=c(1,1),
rhoFn = rhoFn,
gradientFn = gradientFn,
lineSearchFn = gridLineSearch,
testConvergenceFn = testConvergence,
maxIterations = 100,
tolerance = 1E-6,
relative = FALSE,
lambdaStepsize = 0.01,
lambdaMax = 5)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("EconomicMobility.csv")
# Prerequisite functions all of which we discussed in class
gradientDescent <- function(theta,
rhoFn,
gradientFn,
lineSearchFn,
testConvergenceFn,
maxIterations = 100,
tolerance = 1E-6,
relative = FALSE,
lambdaStepsize = 0.01,
lambdaMax = 0.5) {
for (i in 1:maxIterations) {
g         <- gradientFn(theta) # Unnormalized gradient.
glength   <- sqrt(sum(g ^ 2))  # Gradient vector length.
g         <- g / glength       # Unit vector gradient.
lambda    <- lineSearchFn(theta, rhoFn, g,
lambdaStepsize = lambdaStepsize,
lambdaMax = lambdaMax)
thetaNew  <- theta - lambda * g
converged <- testConvergenceFn(thetaNew, theta,
tolerance = tolerance,
relative = relative)
theta = thetaNew #Reza added this update
if (converged) break
}
## Return information about the gradient descent procedure.
return(list(theta = theta, converged = converged,
iteration = i, fnValue = rhoFn(theta)))
}
gridLineSearch <- function(theta,
rhoFn,
g,
lambdaStepsize = 0.01,
lambdaMax = 1) {
## Define equally-spaced grid of lambdas to search over.
lambdas <- seq(from = 0, by = lambdaStepsize, to = lambdaMax)
## Evaluate the objective rho at each such lambda.
rhoVals <- Map(function(lambda) {rhoFn(theta - lambda * g)}, lambdas)
## Return the lambda that gave the minimum objective.
return(lambdas[which.min(rhoVals)])
}
testConvergence <- function(thetaNew,
thetaOld,
tolerance = 1E-10,
relative = FALSE) {
sum(abs(thetaNew - thetaOld)) <
if (relative) tolerance * sum(abs(thetaOld)) else tolerance
}
rhoFn <- function(x) {
alpha <- x[1]
beta <- x[2]
loglikelihood <- 0
P <- data$Commute
for (y in P) {
loglikelihood <- loglikelihood + alpha*log(beta) + (alpha -1)*log(y) - log(gamma(alpha)) - y*beta
}
return(loglikelihood)
}
gradientFn <- function(x) {
alpha <- x[1]
beta <- x[2]
result1 = result2 = 0
P <- data$Commute
for (y in P) {
result1 = result1 + log(beta) + log(y) - digamma(alpha)
result2 = result2 + alpha/beta - y
}
return(c(result1, result2))
}
result <- gradientDescent(theta=c(1,1),
rhoFn = rhoFn,
gradientFn = gradientFn,
lineSearchFn = gridLineSearch,
testConvergenceFn = testConvergence,
lambdaMax = 5)
knitr::opts_chunk$set(echo = TRUE)
data <- read.csv("EconomicMobility.csv")
# Prerequisite functions all of which we discussed in class
gradientDescent <- function(theta,
rhoFn,
gradientFn,
lineSearchFn,
testConvergenceFn,
maxIterations = 100,
tolerance = 1E-6,
relative = FALSE,
lambdaStepsize = 0.01,
lambdaMax = 0.5) {
for (i in 1:maxIterations) {
g         <- gradientFn(theta) # Unnormalized gradient.
glength   <- sqrt(sum(g ^ 2))  # Gradient vector length.
g         <- g / glength       # Unit vector gradient.
lambda    <- lineSearchFn(theta, rhoFn, g,
lambdaStepsize = lambdaStepsize,
lambdaMax = lambdaMax)
thetaNew  <- theta - lambda * g
converged <- testConvergenceFn(thetaNew, theta,
tolerance = tolerance,
relative = relative)
theta = thetaNew #Reza added this update
if (converged) break
}
## Return information about the gradient descent procedure.
return(list(theta = theta, converged = converged,
iteration = i, fnValue = rhoFn(theta)))
}
gridLineSearch <- function(theta,
rhoFn,
g,
lambdaStepsize = 0.01,
lambdaMax = 1) {
## Define equally-spaced grid of lambdas to search over.
lambdas <- seq(from = 0, by = lambdaStepsize, to = lambdaMax)
## Evaluate the objective rho at each such lambda.
rhoVals <- Map(function(lambda) {rhoFn(theta - lambda * g)}, lambdas)
## Return the lambda that gave the minimum objective.
return(lambdas[which.min(rhoVals)])
}
testConvergence <- function(thetaNew,
thetaOld,
tolerance = 1E-10,
relative = FALSE) {
sum(abs(thetaNew - thetaOld)) <
if (relative) tolerance * sum(abs(thetaOld)) else tolerance
}
rhoFn <- function(x) {
alpha <- x[1]
beta <- x[2]
loglikelihood <- 0
P <- data$Commute
for (y in P) {
loglikelihood <- loglikelihood + alpha*log(beta) + (alpha -1)*log(y) - log(gamma(alpha)) - y*beta
}
return(loglikelihood)
}
gradientFn <- function(x) {
alpha <- x[1]
beta <- x[2]
result1 = 0
result2 = 0
P <- data$Commute
for (y in P) {
result1 = result1 + log(beta) + log(y) - digamma(alpha)
result2 = result2 + alpha/beta - y
}
return(c(result1, result2))
}
theta <- c(1,1)
result <- gradientDescent(theta=theta,
rhoFn = rhoFn,
gradientFn = gradientFn,
lineSearchFn = gridLineSearch,
testConvergenceFn = testConvergence,
lambdaMax = 5)
